import pandas as pd

p = os.path.dirname(os.getcwd())
sys.path.append(p)

from utils import *
from sm_utils import *
from bc_utils import *


configfile: 'configs/config.yml'

# variables to change (again these could go in
# a future analysis spec)
config_tsv = 'configs/test_2.tsv'
sample_csv = 'configs/sample_metadata.csv'
kit = 'WT_mega'
chemistry = 'v2'

# read in config / analysis spec
df = parse_config(config_tsv)
bc_df = get_bc1_matches(kit, chemistry)
sample_df = pd.read_csv(sample_csv)

wildcard_constraints:
    plate='|'.join([re.escape(x) for x in df.plate.tolist()]),
    subpool='|'.join([re.escape(x) for x in df.subpool.tolist()]),
    lane='|'.join([re.escape(x) for x in df.lane.tolist()])

rule all:
    input:
        expand(config['filter']['adata'],
               zip,
               plate=df.plate.tolist(),
               subpool=df.subpool.tolist())

###############################
### Ref download and generation
###############################

rule dl:
   resources:
       mem_gb = 4,
       threads = 1
   shell:
       "wget -O {output.out} {params.link}"

use rule dl as dl_annot with:
    params:
        link = config['ref']['annot_link']
    output:
        out = config['ref']['annot']

use rule dl as dl_annot with:
    params:
        link = config['ref']['fa_link']
    output:
        out = config['ref']['fa']

rule kallisto_ind:
    input:
        annot = config['ref']['annot'],
        fa = config['ref']['fa']
    conda:
        "hpc3sc"
    resources:
        mem_gb = 16,
        threads = 8
    output:
        t2g = config['ref']['kallisto']['t2g'],
        ind = config['ref']['kallisto']['ind'],
        fa = config['ref']['kallisto']['fa']
    shell:
        """
        kb ref \
            -i {output.ind} \
            -g {output.t2g} \
            -f1 {output.fa} \
            {input.fa} \
            {input.annot}
        """


##################################

rule symlink_fastq_r1:
    params:
        fastq = lambda wc:get_df_info(wc, df, 'fastq')
    resources:
        mem_gb = 4,
        threads = 1
    output:
        fastq = config['raw']['r1_fastq']
    shell:
        """
        ln -s {params.fastq} {output.fastq}
        """

rule symlink_fastq_r2:
    params:
        fastq = lambda wc:get_df_info(wc, df, 'r2_fastq')
    resources:
        mem_gb = 4,
        threads = 1
    output:
        fastq = config['raw']['r2_fastq']
    shell:
        """
        ln -s {params.fastq} {output.fastq}
        """

rule kallisto:
    input:
        r1_fastq = lambda wc:get_subpool_fastqs(wc, df, config, how='list', read='R1'),
        r2_fastq = lambda wc:get_subpool_fastqs(wc, df, config, how='list', read='R2')
    conda:
        "hpc3sc"
    params:
        bc1_map = config['ref']['bc1_map'],
        barcodes = config['ref']['barcodes'],
        t2g = config['ref']['kallisto']['t2g'],
        ind = config['ref']['kallisto']['ind'],
        c1 = config['ref']['c1'],
        c2 = config['ref']['c2'],
        fastq_str = lambda wc:get_subpool_fastqs(wc, df, config, how='str'),
        odir = config['kallisto']['cgb'].split('counts_unfiltered_modified/')[0]
    resources:
        mem_gb = 250,
        threads = 24
    output:
        config['kallisto']['cgb'],
        config['kallisto']['cggn'],
        config['kallisto']['cgg'],
        config['kallisto']['cgn']
    shell:
        """
        kb count \
            --h5ad \
        	--gene-names \
        	--sum=nucleus \
        	--strand=forward \
        	-r {params.bc1_map} \
        	-w {params.barcodes} \
        	--workflow=nac \
        	-g {params.t2g} \
        	-x SPLIT-SEQ \
        	-i {params.ind} \
        	-t {resources.threads} \
        	-o {params.odir} \
        	-c1 {params.c1} \
        	-c2 {params.c2} \
        	{params.fastq_str}
        """

rule make_subpool_adata:
    input:
        adata = config['kallisto']['adata'],
        cgg = config['kallisto']['cgg']
    params:
        min_counts = 500
    resources:
        mem_gb = 128,
        threads = 4
    output:
        adata = config['filter']['adata']
    run:
        make_subpool_adata(input.adata,
                         input.cgg,
                         wildcards,
                         bc_df,
                         sample_df,
                         params.min_counts,
                         output.adata)

# rule scrublet:
#     input:
#     params:
#     resources:
#     output:
